# -*- coding: utf-8 -*-
"""3 transformers.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G64Y0M0X1urJGrCNw2yLUgzLFsGci-iq
"""

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

import numpy as np

import pandas as pd

# Load the Excel file
file_path = '/kaggle/input/urdu-classification/Urdu events sheet by sheet_Preprocessed.xlsx'
xls = pd.ExcelFile(file_path)

# List all sheet names to understand the structure
sheet_names = xls.sheet_names
sheet_names

# Load each sheet into a separate dataframe
dataframes = {}
for sheet_name in xls.sheet_names:
    dataframes[sheet_name] = pd.read_excel(xls, sheet_name)

# Display the first few rows of each dataframe
for sheet_name, df in dataframes.items():
    print(f"--- {sheet_name} ---")
    print(df.head())
    print("\n")

# Concatenate all dataframes into a single dataframe
combined_df = pd.concat(dataframes.values(), ignore_index=True)

# Display the first few rows of the combined dataframe
print(combined_df.head())

# Display basic statistics for the combined dataframe
print(combined_df.describe())

combined_df_cleaned = combined_df.dropna()

combined_df_filled = combined_df.fillna('')

import pandas as pd
import re
import matplotlib.pyplot as plt

# Provided set of Urdu stop words
urdu_stop_words = set([
    "اور", "خو", "گی", "رہی", "هگر", "تک", "طرف", "پر",
    "ایک", "ہیں", "ہو", "رہے", "هیں", "کی", "در", "اچھی",
    "تھے", "دی", "گے", "لگیں", "ہے", "ہوا", "ہر", "اچھے",
    "رکھ", "کیوں", "کوئی", "والے", "یہ", "کے", "چلے", "تو",
    "پھر", "کررہی", "لگی", "کررہے", "رکھتی", "چلو", "کہ", "ہیں"
])

# Class labels mapping
class_labels = {
    'terrorist attack 1': 'Terrorist attack',
    'national 2': 'National News',
    'sports 3': 'Sports',
    'entertainment 4': 'Entertainment',
    'politics 5': 'Politics',
    'farad 6': 'Fraud and Corruption',
    'sexual 7': 'Sexual Assault',
    'weather 8': 'Weather',
    'accidents 9': 'Accidents',
    'forces 10': 'Forces',
    'inflation 11': 'Inflation',
    'murder 12': 'Murder and Death',
    'education 13': 'Education',
    'law and order 14': 'Law and Order',
    'Social media 15': 'Social Media',
    'earthquakes 16': 'Earthquakes'
}

# Preprocessing function
def preprocess_text(text):
    # Tokenization (simple whitespace tokenization)
    tokens = text.split()

    # Stop Words Elimination
    tokens = [word for word in tokens if word not in urdu_stop_words]

    # Remove Special Characters and Punctuation Marks
    tokens = [re.sub(r'\W', '', word) for word in tokens if word]

    # Join tokens back to a single string
    cleaned_text = ' '.join(tokens)

    return cleaned_text

# Apply preprocessing and add class labels to each sheet
for sheet_name, df in dataframes.items():
    df['cleaned_text'] = df.iloc[:, 0].astype(str).apply(preprocess_text)
    df['class'] = class_labels[sheet_name]
    dataframes[sheet_name] = df

# Combine the cleaned dataframes
combined_cleaned_df = pd.concat([df[['cleaned_text', 'class']] for df in dataframes.values()], ignore_index=True)

# Plot the distribution of classes
class_distribution = combined_cleaned_df['class'].value_counts()
class_distribution.plot(kind='bar')
plt.xlabel('Class')
plt.ylabel('Number of Sentences')
plt.title('Distribution of Sentences Across Classes')
plt.xticks(rotation=45)
plt.show()


# Get the distribution of classes
class_distribution = combined_cleaned_df['class'].value_counts()

# Print the distribution of classes
print("Distribution of Sentences Across Classes:")
for class_name, count in class_distribution.items():
    print(f"{class_name}: {count}")

from wordcloud import WordCloud

# Generate word clouds for each class
for class_name in combined_cleaned_df['class'].unique():
    class_text = ' '.join(combined_cleaned_df[combined_cleaned_df['class'] == class_name]['cleaned_text'])
    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap='viridis').generate(class_text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f'Word Cloud for {class_name}')
    plt.axis('off')
    plt.show()

"""##Data Preperation for Modeling"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(combined_cleaned_df['cleaned_text'], combined_cleaned_df['class'], test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
vectorizer = TfidfVectorizer(max_features=10000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

"""Data Preperation"""

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split

# Define the maximum number of words and maximum sequence length
max_words = 10000
max_len = 100

# Tokenize the text data
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(combined_cleaned_df['cleaned_text'])

# Convert text to sequences
sequences = tokenizer.texts_to_sequences(combined_cleaned_df['cleaned_text'])

# Pad sequences
X = pad_sequences(sequences, maxlen=max_len)

# Convert class labels to numeric
class_labels = combined_cleaned_df['class'].unique()
label_map = {label: idx for idx, label in enumerate(class_labels)}
y = combined_cleaned_df['class'].map(label_map).values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convert labels to one-hot encoding
from tensorflow.keras.utils import to_categorical
y_train = to_categorical(y_train, num_classes=len(class_labels))
y_test = to_categorical(y_test, num_classes=len(class_labels))

"""# To apply "DistilBert"
"""

# Step 1: Install Necessary Libraries
!pip install transformers torch pandas scikit-learn matplotlib seaborn

"""#Step 2: Load and Preprocess the Data"""

import torch
from transformers import DistilBertTokenizer
from sklearn.model_selection import train_test_split

# Convert class labels to numeric
class_labels = combined_cleaned_df['class'].unique()
label_map = {label: idx for idx, label in enumerate(class_labels)}
combined_cleaned_df['label'] = combined_cleaned_df['class'].map(label_map)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    combined_cleaned_df['cleaned_text'].tolist(),  # Ensure lists
    combined_cleaned_df['label'].tolist(),         # Ensure lists
    test_size=0.2,
    random_state=42
)

"""Step 3: Tokenize the Data using DistilBERT Tokenizer"""

# Load the DistilBERT tokenizer
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')

# Define the tokenization function
def tokenize_data(texts, labels, max_length=128):
    input_ids = []
    attention_masks = []

    for text in texts:
        encoded_data = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_length,
            padding='max_length',  # Updated to use padding='max_length'
            truncation=True,       # Added truncation=True
            return_attention_mask=True,
            return_tensors='pt'
        )

        input_ids.append(encoded_data['input_ids'])
        attention_masks.append(encoded_data['attention_mask'])

    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0), torch.tensor(labels)

# Tokenize train and test data
X_train_ids, X_train_masks, y_train = tokenize_data(X_train, y_train)
X_test_ids, X_test_masks, y_test = tokenize_data(X_test, y_test)

"""# Step 4: Create a PyTorch Dataset and DataLoader"""

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

# Create TensorDataset and DataLoader
train_dataset = TensorDataset(X_train_ids, X_train_masks, y_train)
test_dataset = TensorDataset(X_test_ids, X_test_masks, y_test)

train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=32)
test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=32)

"""# Step 5: Define the DistilBERT Model"""

from transformers import DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup

# Load the DistilBERT model for sequence classification
model = DistilBertForSequenceClassification.from_pretrained(
    'distilbert-base-multilingual-cased',
    num_labels=len(class_labels)
)

# Use GPU if available
device = torch.device("cuda")
model.to(device)

"""# Step 6: Train the Model"""

from tqdm import tqdm
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

# Optimizer and learning rate scheduler
optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)
epochs = 1
total_steps = len(train_dataloader) * epochs
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# Track training and validation loss and accuracy
training_stats = {
    'train_loss': [],
    'val_loss': [],
    'train_acc': [],
    'val_acc': []
}

# Training loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    correct_predictions = 0

    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))
    for step, batch in progress_bar:
        batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

        model.zero_grad()
        outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
        loss = outputs.loss
        total_loss += loss.item()

        logits = outputs.logits
        preds = torch.argmax(logits, dim=1).flatten()
        correct_predictions += (preds == batch_labels).sum().item()

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()

        progress_bar.set_description(f'Epoch {epoch+1}/{epochs}')
        progress_bar.set_postfix({'Training Loss': loss.item()})

    avg_train_loss = total_loss / len(train_dataloader)
    train_acc = correct_predictions / len(train_dataloader.dataset)

    # Validation
    model.eval()
    total_loss = 0
    correct_predictions = 0

    progress_bar = tqdm(test_dataloader, total=len(test_dataloader))
    with torch.no_grad():
        for batch in progress_bar:
            batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

            outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
            loss = outputs.loss
            total_loss += loss.item()

            logits = outputs.logits
            preds = torch.argmax(logits, dim=1).flatten()
            correct_predictions += (preds == batch_labels).sum().item()

            progress_bar.set_postfix({'Validation Loss': loss.item()})

    avg_val_loss = total_loss / len(test_dataloader)
    val_acc = correct_predictions / len(test_dataloader.dataset)

    training_stats['train_loss'].append(avg_train_loss)
    training_stats['val_loss'].append(avg_val_loss)
    training_stats['train_acc'].append(train_acc)
    training_stats['val_acc'].append(val_acc)

    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Training Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}')

"""# Step 7: Evaluate the Model"""

import numpy as np# Evaluate the model
model.eval()
predictions = []
true_labels = []
y_pred_probs = []

with torch.no_grad():
    for batch in test_dataloader:
        batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

        outputs = model(batch_input_ids, attention_mask=batch_input_mask)
        logits = outputs.logits
        y_pred_probs.append(logits.cpu().numpy())
        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())
        true_labels.extend(batch_labels.cpu().numpy())

# Convert y_pred_probs to numpy array
y_pred_probs = np.concatenate(y_pred_probs, axis=0)

# Compute accuracy
accuracy = accuracy_score(true_labels, predictions)
print(f'Accuracy: {accuracy:.4f}')

# Classification report
from sklearn.metrics import classification_report
print(classification_report(true_labels, predictions, target_names=class_labels))

# Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

conf_matrix = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()


import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score

# ROC AUC Curve
fpr = {}
tpr = {}
roc_auc = {}

for i, label in enumerate(class_labels):
    fpr[i], tpr[i], _ = roc_curve(np.array(true_labels) == i, y_pred_probs[:, i])
    roc_auc[i] = roc_auc_score(np.array(true_labels) == i, y_pred_probs[:, i])

plt.figure(figsize=(10, 8))
for i, label in enumerate(class_labels):
    plt.plot(fpr[i], tpr[i], label=f'{label} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curve')
plt.legend(loc='lower right')
plt.show()

"""# Camem Bert"""

!pip install transformers torch pandas scikit-learn matplotlib seaborn

import torch
from transformers import CamembertTokenizer, CamembertForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split

# Convert class labels to numeric
label_map = {label: idx for idx, label in enumerate(class_labels)}
combined_cleaned_df['label'] = combined_cleaned_df['class'].map(label_map)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    combined_cleaned_df['cleaned_text'].tolist(),
    combined_cleaned_df['label'].tolist(),
    test_size=0.2,
    random_state=42
)

# Load the CamemBERT tokenizer
tokenizer = CamembertTokenizer.from_pretrained('camembert-base')

# Define the tokenization function
def tokenize_data(texts, labels, max_length=128):
    input_ids = []
    attention_masks = []

    for text in texts:
        encoded_data = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_length,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )

        input_ids.append(encoded_data['input_ids'])
        attention_masks.append(encoded_data['attention_mask'])

    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0), torch.tensor(labels)

# Tokenize train and test data
X_train_ids, X_train_masks, y_train = tokenize_data(X_train, y_train)
X_test_ids, X_test_masks, y_test = tokenize_data(X_test, y_test)

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

# Create TensorDataset and DataLoader
train_dataset = TensorDataset(X_train_ids, X_train_masks, y_train)
test_dataset = TensorDataset(X_test_ids, X_test_masks, y_test)

batch_size = 32
train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)
test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)

# Load the CamemBERT model
model = CamembertForSequenceClassification.from_pretrained(
    'camembert-base',
    num_labels=len(class_labels)
)
# Use GPU if available
device = torch.device("cuda")
model.to(device)

# Optimizer and learning rate scheduler
optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)
epochs = 2
total_steps = len(train_dataloader) * epochs
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# Track training and validation loss and accuracy
training_stats = {
    'train_loss': [],
    'val_loss': [],
    'train_acc': [],
    'val_acc': []
}

# Training loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    correct_predictions = 0

    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))
    for step, batch in progress_bar:
        batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

        model.zero_grad()
        outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
        loss = outputs.loss
        total_loss += loss.item()

        logits = outputs.logits
        preds = torch.argmax(logits, dim=1).flatten()
        correct_predictions += (preds == batch_labels).sum().item()

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()

        progress_bar.set_description(f'Epoch {epoch+1}/{epochs}')
        progress_bar.set_postfix({'Training Loss': loss.item()})

    avg_train_loss = total_loss / len(train_dataloader)
    train_acc = correct_predictions / len(train_dataloader.dataset)

    # Validation
    model.eval()
    total_loss = 0
    correct_predictions = 0

    progress_bar = tqdm(test_dataloader, total=len(test_dataloader))
    with torch.no_grad():
        for batch in progress_bar:
            batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

            outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
            loss = outputs.loss
            total_loss += loss.item()

            logits = outputs.logits
            preds = torch.argmax(logits, dim=1).flatten()
            correct_predictions += (preds == batch_labels).sum().item()

            progress_bar.set_postfix({'Validation Loss': loss.item()})

    avg_val_loss = total_loss / len(test_dataloader)
    val_acc = correct_predictions / len(test_dataloader.dataset)

    training_stats['train_loss'].append(avg_train_loss)
    training_stats['val_loss'].append(avg_val_loss)
    training_stats['train_acc'].append(train_acc)
    training_stats['val_acc'].append(val_acc)

    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Training Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}')

# Evaluate the model
model.eval()
predictions = []
true_labels = []
y_pred_probs = []

with torch.no_grad():
    for batch in test_dataloader:
        batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

        outputs = model(batch_input_ids, attention_mask=batch_input_mask)
        logits = outputs.logits
        y_pred_probs.append(logits.cpu().numpy())
        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())
        true_labels.extend(batch_labels.cpu().numpy())

# Convert y_pred_probs to numpy array
y_pred_probs = np.concatenate(y_pred_probs, axis=0)

# Compute accuracy
accuracy = accuracy_score(true_labels, predictions)
print(f'Accuracy: {accuracy:.4f}')

# Classification report
from sklearn.metrics import classification_report
print(classification_report(true_labels, predictions, target_names=class_labels))

# Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score

conf_matrix = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ROC AUC Curve
fpr = {}
tpr = {}
roc_auc = {}

for i, label in enumerate(class_labels):
    fpr[i], tpr[i], _ = roc_curve(np.array(true_labels) == i, y_pred_probs[:, i])
    roc_auc[i] = roc_auc_score(np.array(true_labels) == i, y_pred_probs[:, i])

plt.figure(figsize=(10, 8))
for i, label in enumerate(class_labels):
    plt.plot(fpr[i], tpr[i], label=f'{label} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curve')
plt.legend(loc='lower right')
plt.show()

"""# XLM-R (Cross-lingual Language Model - RoBERTa):"""

!pip install transformers torch pandas scikit-learn matplotlib seaborn

import torch
from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup
from sklearn.model_selection import train_test_split

# Convert class labels to numeric
label_map = {label: idx for idx, label in enumerate(class_labels)}
combined_cleaned_df['label'] = combined_cleaned_df['class'].map(label_map)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    combined_cleaned_df['cleaned_text'].tolist(),
    combined_cleaned_df['label'].tolist(),
    test_size=0.2,
    random_state=42
)

# Load the XLM-RoBERTa tokenizer
tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')

# Define the tokenization function
def tokenize_data(texts, labels, max_length=128):
    input_ids = []
    attention_masks = []

    for text in texts:
        encoded_data = tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=max_length,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )

        input_ids.append(encoded_data['input_ids'])
        attention_masks.append(encoded_data['attention_mask'])

    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0), torch.tensor(labels)

# Tokenize train and test data
X_train_ids, X_train_masks, y_train = tokenize_data(X_train, y_train)
X_test_ids, X_test_masks, y_test = tokenize_data(X_test, y_test)

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

# Create TensorDataset and DataLoader
train_dataset = TensorDataset(X_train_ids, X_train_masks, y_train)
test_dataset = TensorDataset(X_test_ids, X_test_masks, y_test)

batch_size = 32
train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)
test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

# Create TensorDataset and DataLoader
train_dataset = TensorDataset(X_train_ids, X_train_masks, y_train)
test_dataset = TensorDataset(X_test_ids, X_test_masks, y_test)

batch_size = 32
train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)
test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)

# Load the XLM-RoBERTa model
model = XLMRobertaForSequenceClassification.from_pretrained(
    'xlm-roberta-base',
    num_labels=len(class_labels)
)

# Use GPU if available
device = torch.device("cuda")
model.to(device)

from tqdm import tqdm# Optimizer and learning rate scheduler
optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)
epochs = 1
total_steps = len(train_dataloader) * epochs
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# Track training and validation loss and accuracy
training_stats = {
    'train_loss': [],
    'val_loss': [],
    'train_acc': [],
    'val_acc': []
}

# Training loop
for epoch in range(epochs):
    model.train()
    total_loss = 0
    correct_predictions = 0

    progress_bar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))
    for step, batch in progress_bar:
        batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

        model.zero_grad()
        outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
        loss = outputs.loss
        total_loss += loss.item()

        logits = outputs.logits
        preds = torch.argmax(logits, dim=1).flatten()
        correct_predictions += (preds == batch_labels).sum().item()

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()

        progress_bar.set_description(f'Epoch {epoch+1}/{epochs}')
        progress_bar.set_postfix({'Training Loss': loss.item()})

    avg_train_loss = total_loss / len(train_dataloader)
    train_acc = correct_predictions / len(train_dataloader.dataset)

    # Validation
    model.eval()
    total_loss = 0
    correct_predictions = 0

    progress_bar = tqdm(test_dataloader, total=len(test_dataloader))
    with torch.no_grad():
        for batch in progress_bar:
            batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

            outputs = model(batch_input_ids, attention_mask=batch_input_mask, labels=batch_labels)
            loss = outputs.loss
            total_loss += loss.item()

            logits = outputs.logits
            preds = torch.argmax(logits, dim=1).flatten()
            correct_predictions += (preds == batch_labels).sum().item()

            progress_bar.set_postfix({'Validation Loss': loss.item()})

    avg_val_loss = total_loss / len(test_dataloader)
    val_acc = correct_predictions / len(test_dataloader.dataset)

    training_stats['train_loss'].append(avg_train_loss)
    training_stats['val_loss'].append(avg_val_loss)
    training_stats['train_acc'].append(train_acc)
    training_stats['val_acc'].append(val_acc)

    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Training Accuracy: {train_acc:.4f}, Validation Accuracy: {val_acc:.4f}')

# Evaluate the model
model.eval()
predictions = []
true_labels = []
y_pred_probs = []

with torch.no_grad():
    for batch in test_dataloader:
        batch_input_ids, batch_input_mask, batch_labels = tuple(t.to(device) for t in batch)

        outputs = model(batch_input_ids, attention_mask=batch_input_mask)
        logits = outputs.logits
        y_pred_probs.append(logits.cpu().numpy())
        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())
        true_labels.extend(batch_labels.cpu().numpy())

# Convert y_pred_probs to numpy array
y_pred_probs = np.concatenate(y_pred_probs, axis=0)

# Compute accuracy
accuracy = accuracy_score(true_labels, predictions)
print(f'Accuracy: {accuracy:.4f}')

# Classification report
from sklearn.metrics import classification_report
print(classification_report(true_labels, predictions, target_names=class_labels))

# Confusion Matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score

conf_matrix = confusion_matrix(true_labels, predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# ROC AUC Curve
fpr = {}
tpr = {}
roc_auc = {}

for i, label in enumerate(class_labels):
    fpr[i], tpr[i], _ = roc_curve(np.array(true_labels) == i, y_pred_probs[:, i])
    roc_auc[i] = roc_auc_score(np.array(true_labels) == i, y_pred_probs[:, i])

plt.figure(figsize=(10, 8))
for i, label in enumerate(class_labels):
    plt.plot(fpr[i], tpr[i], label=f'{label} (AUC = {roc_auc[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curve')
plt.legend(loc='lower right')
plt.show()



